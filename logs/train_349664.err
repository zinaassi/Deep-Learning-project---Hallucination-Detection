2026-01-23 21:10:33,633 - AppLogger - [INFO] - main.py:247 - Starting the data processing pipeline.
2026-01-23 21:10:33,634 - AppLogger - [INFO] - main.py:248 - Parsed Arguments: {'LLM': 'meta-llama/Meta-Llama-3-8B-Instruct', 'base_raw_data_dir': '/home/guy_b/big-storage/raw_data', 'train_dataset': 'imdb', 'test_dataset': 'imdb_test', 'base_pre_processed_data_dir': '/home/zina.assi/Deep-Learning-project---Hallucination-Detection/data/pre_processed_data', 'probe_model': 'ImprovedLOSNet', 'topk_preprocess': 1000, 'input_output_type': 'output', 'topk_dim': 1000, 'N_max': 100, 'num_folds': 5, 'fold_to_run': 0, 'input_type': 'LOS', 'seed': 0, 'cuda_idx': 0, 'batch_size': 64, 'hidden_dim': 128, 'heads': 8, 'dropout': 0.1, 'num_layers': 2, 'pool': 'cls', 'patience': 20, 'num_epochs': 100, 'best_model_path': 'saved_models', 'lr': 0.0001, 'rank_encoding': 'scale_encoding', 'weight_decay': 0.001, 'num_workers': 4, 'pin_memory': 1, 'rank_embed_dim': 128, 'use_rank_embed': True, 'use_entropy': True, 'use_gaps': True, 'distill_alpha': 0.5, 'distill_temp': 2.0}
2026-01-23 21:10:33,635 - AppLogger - [INFO] - main.py:255 - Loading preproccessed data for model 'meta-llama/Meta-Llama-3-8B-Instruct'
2026-01-23 21:10:33,637 - AppLogger - [INFO] - main.py:25 - Starting data preparation for model 'meta-llama/Meta-Llama-3-8B-Instruct' using training dataset 'imdb'.
2026-01-23 21:10:33,646 - AppLogger - [INFO] - main.py:91 - Training dataset loaded successfully.
2026-01-23 21:10:33,714 - AppLogger - [INFO] - main.py:100 - Test dataset loaded successfully.
2026-01-23 21:10:33,716 - AppLogger - [INFO] - main.py:102 - Dataset processing pipeline completed successfully.
2026-01-23 21:10:33,717 - AppLogger - [INFO] - main.py:260 - Splitting dataset into train, validation, and test indices.
Extracting labels:   0%|          | 0/1000 [00:00<?, ?it/s]Extracting labels:   1%|▏         | 14/1000 [00:00<00:07, 133.45it/s]Extracting labels:   3%|▎         | 29/1000 [00:00<00:07, 135.36it/s]Extracting labels:   4%|▍         | 43/1000 [00:00<00:08, 111.53it/s]Extracting labels:   6%|▌         | 55/1000 [00:00<00:11, 85.38it/s] Extracting labels:   6%|▋         | 65/1000 [00:00<00:12, 75.53it/s]Extracting labels:   7%|▋         | 74/1000 [00:00<00:14, 62.24it/s]Extracting labels:   8%|▊         | 82/1000 [00:01<00:14, 64.41it/s]Extracting labels:   9%|▉         | 89/1000 [00:01<00:14, 63.38it/s]Extracting labels:  10%|▉         | 96/1000 [00:01<00:14, 60.81it/s]Extracting labels:  10%|█         | 104/1000 [00:01<00:13, 64.81it/s]Extracting labels:  11%|█         | 111/1000 [00:01<00:13, 64.48it/s]Extracting labels:  12%|█▏        | 118/1000 [00:01<00:15, 58.23it/s]Extracting labels:  13%|█▎        | 126/1000 [00:01<00:14, 59.20it/s]Extracting labels:  14%|█▎        | 135/1000 [00:01<00:13, 64.78it/s]Extracting labels:  14%|█▍        | 142/1000 [00:02<00:14, 57.48it/s]Extracting labels:  15%|█▍        | 148/1000 [00:02<00:15, 56.35it/s]Extracting labels:  15%|█▌        | 154/1000 [00:02<00:15, 55.25it/s]Extracting labels:  16%|█▌        | 162/1000 [00:02<00:13, 60.89it/s]Extracting labels:  17%|█▋        | 172/1000 [00:02<00:11, 70.20it/s]Extracting labels:  18%|█▊        | 183/1000 [00:02<00:10, 78.66it/s]Extracting labels:  20%|█▉        | 195/1000 [00:02<00:08, 89.67it/s]Extracting labels:  21%|██        | 209/1000 [00:02<00:07, 101.49it/s]Extracting labels:  22%|██▏       | 223/1000 [00:02<00:07, 110.60it/s]Extracting labels:  24%|██▎       | 237/1000 [00:03<00:06, 114.19it/s]Extracting labels:  25%|██▍       | 249/1000 [00:03<00:06, 114.74it/s]Extracting labels:  26%|██▋       | 264/1000 [00:03<00:06, 120.33it/s]Extracting labels:  28%|██▊       | 277/1000 [00:03<00:06, 116.74it/s]Extracting labels:  29%|██▉       | 289/1000 [00:03<00:06, 115.48it/s]Extracting labels:  30%|███       | 301/1000 [00:03<00:06, 104.05it/s]Extracting labels:  32%|███▏      | 315/1000 [00:03<00:06, 113.17it/s]Extracting labels:  33%|███▎      | 328/1000 [00:03<00:05, 117.00it/s]Extracting labels:  34%|███▍      | 340/1000 [00:03<00:05, 114.90it/s]Extracting labels:  35%|███▌      | 353/1000 [00:04<00:05, 115.76it/s]Extracting labels:  36%|███▋      | 365/1000 [00:04<00:06, 101.11it/s]Extracting labels:  38%|███▊      | 376/1000 [00:04<00:06, 97.22it/s] Extracting labels:  39%|███▉      | 390/1000 [00:04<00:05, 105.31it/s]Extracting labels:  41%|████      | 406/1000 [00:04<00:04, 119.47it/s]Extracting labels:  42%|████▏     | 419/1000 [00:04<00:05, 112.50it/s]Extracting labels:  43%|████▎     | 431/1000 [00:04<00:05, 105.93it/s]Extracting labels:  45%|████▍     | 447/1000 [00:04<00:04, 119.56it/s]Extracting labels:  46%|████▌     | 461/1000 [00:05<00:04, 124.04it/s]Extracting labels:  48%|████▊     | 475/1000 [00:05<00:04, 128.25it/s]Extracting labels:  49%|████▉     | 490/1000 [00:05<00:03, 132.07it/s]Extracting labels:  50%|█████     | 504/1000 [00:05<00:03, 133.57it/s]Extracting labels:  52%|█████▏    | 518/1000 [00:05<00:03, 128.60it/s]Extracting labels:  53%|█████▎    | 534/1000 [00:05<00:03, 136.82it/s]Extracting labels:  55%|█████▌    | 550/1000 [00:05<00:03, 143.29it/s]Extracting labels:  56%|█████▋    | 565/1000 [00:05<00:03, 129.42it/s]Extracting labels:  58%|█████▊    | 581/1000 [00:05<00:03, 135.71it/s]Extracting labels:  60%|█████▉    | 595/1000 [00:06<00:03, 129.47it/s]Extracting labels:  61%|██████    | 609/1000 [00:06<00:03, 114.13it/s]Extracting labels:  62%|██████▏   | 621/1000 [00:06<00:03, 114.70it/s]Extracting labels:  64%|██████▎   | 635/1000 [00:06<00:03, 120.48it/s]Extracting labels:  65%|██████▍   | 648/1000 [00:06<00:03, 114.58it/s]Extracting labels:  66%|██████▋   | 664/1000 [00:06<00:02, 121.73it/s]Extracting labels:  68%|██████▊   | 677/1000 [00:06<00:02, 120.47it/s]Extracting labels:  69%|██████▉   | 690/1000 [00:06<00:02, 118.18it/s]Extracting labels:  70%|███████   | 703/1000 [00:06<00:02, 119.68it/s]Extracting labels:  72%|███████▏  | 719/1000 [00:07<00:02, 120.02it/s]Extracting labels:  73%|███████▎  | 732/1000 [00:07<00:02, 121.06it/s]Extracting labels:  74%|███████▍  | 745/1000 [00:07<00:02, 120.24it/s]Extracting labels:  76%|███████▌  | 761/1000 [00:07<00:01, 128.29it/s]Extracting labels:  78%|███████▊  | 777/1000 [00:07<00:01, 134.87it/s]Extracting labels:  79%|███████▉  | 791/1000 [00:07<00:01, 131.70it/s]Extracting labels:  80%|████████  | 805/1000 [00:07<00:01, 127.03it/s]Extracting labels:  82%|████████▏ | 820/1000 [00:07<00:01, 132.81it/s]Extracting labels:  83%|████████▎ | 834/1000 [00:07<00:01, 128.37it/s]Extracting labels:  85%|████████▍ | 847/1000 [00:08<00:01, 125.07it/s]Extracting labels:  86%|████████▌ | 860/1000 [00:08<00:01, 122.15it/s]Extracting labels:  87%|████████▋ | 873/1000 [00:08<00:01, 122.79it/s]Extracting labels:  89%|████████▊ | 886/1000 [00:08<00:00, 124.48it/s]Extracting labels:  90%|████████▉ | 899/1000 [00:08<00:00, 112.82it/s]Extracting labels:  91%|█████████ | 911/1000 [00:08<00:00, 109.42it/s]Extracting labels:  92%|█████████▏| 923/1000 [00:08<00:00, 108.36it/s]Extracting labels:  94%|█████████▍| 939/1000 [00:08<00:00, 122.05it/s]Extracting labels:  95%|█████████▌| 954/1000 [00:08<00:00, 127.62it/s]Extracting labels:  97%|█████████▋| 968/1000 [00:09<00:00, 125.67it/s]Extracting labels:  98%|█████████▊| 983/1000 [00:09<00:00, 130.60it/s]Extracting labels: 100%|█████████▉| 998/1000 [00:09<00:00, 135.30it/s]Extracting labels: 100%|██████████| 1000/1000 [00:09<00:00, 107.40it/s]
Processing folds:   0%|          | 0/5 [00:00<?, ?it/s]Processing folds: 100%|██████████| 5/5 [00:00<00:00, 49461.13it/s]
2026-01-23 21:10:43,034 - AppLogger - [INFO] - main.py:276 - Train size: 800, Validation size: 200, Test indices: 1000
2026-01-23 21:10:43,077 - AppLogger - [INFO] - main.py:285 - Running fold 1 of 5.
2026-01-23 21:10:43,079 - AppLogger - [INFO] - main.py:287 - Creating dataloaders for training, validation, and test sets.
2026-01-23 21:10:43,110 - AppLogger - [INFO] - main.py:318 - Creating model for input type: LOS with sequence length 100 and feature dimension: 1000
2026-01-23 21:10:43,379 - AppLogger - [INFO] - main.py:327 - Total number of parameters in the model: 450561
2026-01-23 21:10:43,379 - AppLogger - [INFO] - main.py:330 - Creating optimizer and scheduler.
2026-01-23 21:10:43,381 - AppLogger - [INFO] - main.py:335 - Total number of training steps: 1300, and warm-up steps: 130
2026-01-23 21:10:43,382 - AppLogger - [INFO] - main.py:350 - will save the best model in this folder: saved_models/meta-llama/Meta-Llama-3-8B-Instruct/imdb with this file name: 5443382365.
2026-01-23 21:10:43,383 - AppLogger - [INFO] - main.py:351 - Starting wandb, project is LOS-Net.
2026-01-23 21:10:43,385 - AppLogger - [INFO] - main.py:352 - Starting training loop.
wandb: ERROR api_key not configured (no-tty). call wandb.login(key=[your_api_key])
Traceback (most recent call last):
  File "/home/zina.assi/Deep-Learning-project---Hallucination-Detection/main.py", line 359, in <module>
    main()
  File "/home/zina.assi/Deep-Learning-project---Hallucination-Detection/main.py", line 354, in main
    wandb.init(project="LOS-Net", config=args)
  File "/home/zina.assi/miniconda3/envs/LOS_Net/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 1189, in init
    raise e
  File "/home/zina.assi/miniconda3/envs/LOS_Net/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 1166, in init
    wi.setup(kwargs)
  File "/home/zina.assi/miniconda3/envs/LOS_Net/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 308, in setup
    wandb_login._login(
  File "/home/zina.assi/miniconda3/envs/LOS_Net/lib/python3.10/site-packages/wandb/sdk/wandb_login.py", line 298, in _login
    wlogin.prompt_api_key()
  File "/home/zina.assi/miniconda3/envs/LOS_Net/lib/python3.10/site-packages/wandb/sdk/wandb_login.py", line 228, in prompt_api_key
    raise UsageError("api_key not configured (no-tty). call " + directive)
wandb.errors.UsageError: api_key not configured (no-tty). call wandb.login(key=[your_api_key])
