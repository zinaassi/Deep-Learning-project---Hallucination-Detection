2026-01-23 21:20:39,268 - AppLogger - [INFO] - main.py:247 - Starting the data processing pipeline.
2026-01-23 21:20:39,269 - AppLogger - [INFO] - main.py:248 - Parsed Arguments: {'LLM': 'mistralai/Mistral-7B-Instruct-v0.2', 'base_raw_data_dir': '/home/guy_b/big-storage/raw_data', 'train_dataset': 'imdb', 'test_dataset': 'imdb_test', 'base_pre_processed_data_dir': '/home/zina.assi/Deep-Learning-project---Hallucination-Detection/data/pre_processed_data', 'probe_model': 'ImprovedLOSNet', 'topk_preprocess': 1000, 'input_output_type': 'output', 'topk_dim': 1000, 'N_max': 100, 'num_folds': 5, 'fold_to_run': 0, 'input_type': 'LOS', 'seed': 0, 'cuda_idx': 0, 'batch_size': 64, 'hidden_dim': 128, 'heads': 8, 'dropout': 0.1, 'num_layers': 2, 'pool': 'cls', 'patience': 20, 'num_epochs': 100, 'best_model_path': 'saved_models', 'lr': 0.0001, 'rank_encoding': 'scale_encoding', 'weight_decay': 0.001, 'num_workers': 4, 'pin_memory': 1, 'rank_embed_dim': 128, 'use_rank_embed': True, 'use_entropy': True, 'use_gaps': True, 'distill_alpha': 0.5, 'distill_temp': 2.0}
2026-01-23 21:20:39,270 - AppLogger - [INFO] - main.py:255 - Loading preproccessed data for model 'mistralai/Mistral-7B-Instruct-v0.2'
2026-01-23 21:20:39,271 - AppLogger - [INFO] - main.py:25 - Starting data preparation for model 'mistralai/Mistral-7B-Instruct-v0.2' using training dataset 'imdb'.
2026-01-23 21:20:39,282 - AppLogger - [INFO] - main.py:91 - Training dataset loaded successfully.
2026-01-23 21:20:39,293 - AppLogger - [INFO] - main.py:100 - Test dataset loaded successfully.
2026-01-23 21:20:39,296 - AppLogger - [INFO] - main.py:102 - Dataset processing pipeline completed successfully.
2026-01-23 21:20:39,301 - AppLogger - [INFO] - main.py:260 - Splitting dataset into train, validation, and test indices.
Extracting labels:   0%|          | 0/1000 [00:00<?, ?it/s]Extracting labels:   1%|          | 12/1000 [00:00<00:08, 118.38it/s]Extracting labels:   3%|▎         | 30/1000 [00:00<00:06, 151.45it/s]Extracting labels:   6%|▌         | 59/1000 [00:00<00:04, 213.43it/s]Extracting labels:  11%|█▏        | 113/1000 [00:00<00:02, 340.71it/s]Extracting labels:  17%|█▋        | 167/1000 [00:00<00:02, 411.39it/s]Extracting labels:  22%|██▏       | 221/1000 [00:00<00:01, 452.68it/s]Extracting labels:  28%|██▊       | 275/1000 [00:00<00:01, 480.53it/s]Extracting labels:  33%|███▎      | 329/1000 [00:00<00:01, 498.01it/s]Extracting labels:  38%|███▊      | 381/1000 [00:00<00:01, 503.94it/s]Extracting labels:  44%|████▎     | 435/1000 [00:01<00:01, 514.99it/s]Extracting labels:  49%|████▉     | 491/1000 [00:01<00:00, 528.52it/s]Extracting labels:  55%|█████▍    | 547/1000 [00:01<00:00, 536.47it/s]Extracting labels:  60%|██████    | 604/1000 [00:01<00:00, 544.52it/s]Extracting labels:  66%|██████▌   | 661/1000 [00:01<00:00, 549.30it/s]Extracting labels:  72%|███████▏  | 716/1000 [00:01<00:00, 546.76it/s]Extracting labels:  77%|███████▋  | 773/1000 [00:01<00:00, 553.42it/s]Extracting labels:  83%|████████▎ | 829/1000 [00:01<00:00, 554.23it/s]Extracting labels:  89%|████████▊ | 886/1000 [00:01<00:00, 558.22it/s]Extracting labels:  94%|█████████▍| 942/1000 [00:01<00:00, 557.93it/s]Extracting labels: 100%|█████████▉| 998/1000 [00:02<00:00, 553.88it/s]Extracting labels: 100%|██████████| 1000/1000 [00:02<00:00, 494.17it/s]
Processing folds:   0%|          | 0/5 [00:00<?, ?it/s]Processing folds: 100%|██████████| 5/5 [00:00<00:00, 58254.22it/s]
2026-01-23 21:20:41,330 - AppLogger - [INFO] - main.py:276 - Train size: 800, Validation size: 200, Test indices: 1000
2026-01-23 21:20:41,366 - AppLogger - [INFO] - main.py:285 - Running fold 1 of 5.
2026-01-23 21:20:41,367 - AppLogger - [INFO] - main.py:287 - Creating dataloaders for training, validation, and test sets.
2026-01-23 21:20:41,374 - AppLogger - [INFO] - main.py:318 - Creating model for input type: LOS with sequence length 100 and feature dimension: 1000
2026-01-23 21:20:41,996 - AppLogger - [INFO] - main.py:327 - Total number of parameters in the model: 450561
2026-01-23 21:20:41,997 - AppLogger - [INFO] - main.py:330 - Creating optimizer and scheduler.
2026-01-23 21:20:42,001 - AppLogger - [INFO] - main.py:335 - Total number of training steps: 1300, and warm-up steps: 130
2026-01-23 21:20:42,007 - AppLogger - [INFO] - main.py:350 - will save the best model in this folder: saved_models/mistralai/Mistral-7B-Instruct-v0.2/imdb with this file name: 6042007001.
2026-01-23 21:20:42,014 - AppLogger - [INFO] - main.py:351 - Starting wandb, project is LOS-Net.
2026-01-23 21:20:42,019 - AppLogger - [INFO] - main.py:352 - Starting training loop.
2026-01-23 21:20:43,132 - AppLogger - [INFO] - main.py:190 - Epoch 1/100
Training Progress:   0%|          | 0/13 [00:00<?, ?it/s]Training Progress:   8%|▊         | 1/13 [00:01<00:21,  1.82s/it]Training Progress:  15%|█▌        | 2/13 [00:01<00:08,  1.24it/s]Training Progress:  31%|███       | 4/13 [00:02<00:03,  2.76it/s]Training Progress:  46%|████▌     | 6/13 [00:02<00:01,  4.27it/s]Training Progress:  62%|██████▏   | 8/13 [00:02<00:00,  5.69it/s]Training Progress:  77%|███████▋  | 10/13 [00:02<00:00,  6.95it/s]Training Progress:  92%|█████████▏| 12/13 [00:02<00:00,  7.98it/s]Training Progress: 100%|██████████| 13/13 [00:02<00:00,  4.47it/s]
Traceback (most recent call last):
  File "/home/zina.assi/Deep-Learning-project---Hallucination-Detection/main.py", line 359, in <module>
    main()
  File "/home/zina.assi/Deep-Learning-project---Hallucination-Detection/main.py", line 356, in main
    train_model(logger=logger, model=model, dataloader_train=dataloader_train, dataloader_val=dataloader_val, dataloader_test=dataloader_test, criterion=criterion, optimizer=optimizer, scheduler=scheduler, args=args, device=device)
  File "/home/zina.assi/Deep-Learning-project---Hallucination-Detection/main.py", line 193, in train_model
    train_loss, auc_train = train_one_epoch(model, dataloader_train, criterion, optimizer, scheduler, device, input_type=args.input_type)
  File "/home/zina.assi/Deep-Learning-project---Hallucination-Detection/main.py", line 140, in train_one_epoch
    fpr, tpr, _ = roc_curve(np.array(all_labels, dtype=bool), np.array(all_predictions))
  File "/home/zina.assi/miniconda3/envs/LOS_Net/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/zina.assi/miniconda3/envs/LOS_Net/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 1145, in roc_curve
    fps, tps, thresholds = _binary_clf_curve(
  File "/home/zina.assi/miniconda3/envs/LOS_Net/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 823, in _binary_clf_curve
    assert_all_finite(y_score)
  File "/home/zina.assi/miniconda3/envs/LOS_Net/lib/python3.10/site-packages/sklearn/utils/validation.py", line 213, in assert_all_finite
    _assert_all_finite(
  File "/home/zina.assi/miniconda3/envs/LOS_Net/lib/python3.10/site-packages/sklearn/utils/validation.py", line 123, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/zina.assi/miniconda3/envs/LOS_Net/lib/python3.10/site-packages/sklearn/utils/validation.py", line 172, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.
